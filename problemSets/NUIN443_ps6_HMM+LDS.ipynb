{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMgTv4ma1sYfWqzX9bLqSEk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucas-pinto/NUIN443/blob/main/problemSets/NUIN443_ps6_HMM%2BLDS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Packages**"
      ],
      "metadata": {
        "id": "-iximm4Hj6Ah"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEioygwHj1Qk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Some helper functions for Gaussians\n",
        "from numpy.random import normal, multivariate_normal\n",
        "from scipy.stats import norm\n",
        "\n",
        "#Some scikit learn models we'll be using\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.decomposition import PCA,FactorAnalysis\n",
        "\n",
        "#To load the data file\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Hidden Markov Models"
      ],
      "metadata": {
        "id": "dzOJHb0clN7L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "A) Write code to simulate data from the an HMM with 2 discrete states (indexed by 0 and 1), with 1-dimensional Gaussian observations.\n",
        "<br><br>\n",
        "The initial state probabilities are:<br>\n",
        "$P(z_0=0)=0.5$,\n",
        "$P(z_0=1)=0.5$\n",
        "<br><br>\n",
        "The transitions matrix is:<br>\n",
        "$A = \\begin{bmatrix} 0.9 & 0.1 \\\\ 0.05 & 0.95 \\end{bmatrix}$\n",
        "<br><br>\n",
        "The emissions probabilities are:<br>\n",
        "$P(y|z=0)=\\mathcal{N}(0,1)$\n",
        "<br>\n",
        "$P(y|z=1)=\\mathcal{N}(2,1)$\n",
        "\n",
        "<br><br>\n",
        "We've provided code below that you can fill in (which should hopefully make this faster for you)\n",
        "\n",
        "*Credit: Note that the below code has been adapted from Neuromatch's HMM exercise.*"
      ],
      "metadata": {
        "id": "AeOZO4vVk-Ux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Fill in parameters below##\n",
        "\n",
        "#Initial probabilities\n",
        "initial_probs=\n",
        "\n",
        "#Transition matrix\n",
        "transition_matrix=\n",
        "\n",
        "#Means for the 2 states\n",
        "means=\n",
        "\n",
        "#Variances for the 2 states\n",
        "vars=\n",
        "\n",
        "\n",
        "\n",
        "#Number of time points to run the simulation for\n",
        "T=500\n",
        "\n",
        "\n",
        "#We'll set the random seed so results are reproducible\n",
        "np.random.seed(0)\n",
        "\n",
        "# Initialize the latent (Z) and observation (X)\n",
        "Z = np.zeros((T,),dtype=int)\n",
        "X = np.zeros((T,))\n",
        "\n",
        "\n",
        "\n",
        "# Sample initial (time 0) latent state\n",
        "## Fill in the line below##\n",
        "Z[0] = np.random.choice([0,1],p=    )\n",
        "\n",
        "# Given the latent that was just sampled, determine the observation at time 0\n",
        "## Fill in the line below##\n",
        "X[0] = normal()\n",
        "\n",
        "# Loop over time points\n",
        "# At each time point, sample the next latent state (based on the transition matrix and the previous state),\n",
        "# and then determine the observation at that time point\n",
        "for t in range(1,T):\n",
        "\n",
        "  # Determine latent state at time `t`\n",
        "  ## Fill in the line below##\n",
        "  transition_vector =\n",
        "  Z[t] = np.random.choice([0,1],p=transition_vector)\n",
        "\n",
        "  #Given the latent that was just sampled, determine the observation at time t\n",
        "  ## Fill in the line below##\n",
        "  X[t] = normal()"
      ],
      "metadata": {
        "id": "041UbV6cnsBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the code below to plot the latent (Z) and the observations (X)"
      ],
      "metadata": {
        "id": "0eMn3Vf3Pahc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,3))\n",
        "\n",
        "plt.subplot(2,1,1)\n",
        "plt.imshow(Z[None,:],aspect='auto')\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(X)"
      ],
      "metadata": {
        "id": "eTZPTM9FOn2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "B) Fit K-means to the observations. You can use sci-kit learn (imported above)"
      ],
      "metadata": {
        "id": "H51UPZHvRgwv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnBVzCPTQvzg",
        "outputId": "c52b839e-41d1-4bab-ac7b-100ad5ae9ca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the below code to see how the states learned compare to the ground truth HMM states. Change \"Z_kmeans\" to the variable name of the kmeans states you used above."
      ],
      "metadata": {
        "id": "mr8uyXeNR5vs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,3))\n",
        "\n",
        "plt.subplot(2,1,1)\n",
        "plt.imshow(Z[None,:],aspect='auto')\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "plt.imshow(Z_kmeans[None,:],aspect='auto')\n"
      ],
      "metadata": {
        "id": "YMM_TN_8Mb-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "C)Calculate the accuracy of K-means at finding the ground truth HMM states"
      ],
      "metadata": {
        "id": "i2lQb4V0S7Bs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yK8DoPpARQa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "D) We are not going to have you code up the full EM algorithm, but will have you do most of the E step. This will involve the forward/backward algorithm. Assume that you know the HMM parameters (use the ground truth ones).<br>\n",
        "Code up the forward algorithm for HMMs, and use it to calculate \"alphas\" for all time points."
      ],
      "metadata": {
        "id": "qvq-hVkhTcBK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1ULwci3dTNEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the below code to see how the alphas compare to the ground truth HMM states. Change \"alphas\" to the variable name you used above. This is a good sanity check that the above code is correct, since the alphas for one of the states will look somewhat similar to the ground truth (although the values won't always be exactly 0 and 1)."
      ],
      "metadata": {
        "id": "BnjBaMiTnIPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,3))\n",
        "\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(alphas)\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(Z)"
      ],
      "metadata": {
        "id": "cG3Y0kBhf_wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "E) Code up the backward algorithm for HMMs, and use it to calculate \"betas\" for all time points."
      ],
      "metadata": {
        "id": "cacJdu_nozzv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DmL6PFS3gis6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the below code to see how the betas compare to the ground truth HMM states. Change \"betas\" to the variable name you used above. This is a good sanity check that the above code is correct, since the betas for one of the states will look somewhat similar to the ground truth (although the values won't always be exactly 0 and 1 - in fact, for the betas, the values here will be between ~0.1 and 0.9)."
      ],
      "metadata": {
        "id": "rMJhOmZ3qHiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,3))\n",
        "\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(betas)\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(Z)"
      ],
      "metadata": {
        "id": "fVfgMVsjjz8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "F) Run the forward/backward algorithm (combining the steps above) to get the posterior, p(z|x)."
      ],
      "metadata": {
        "id": "x1blBCCuqeZK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uARCd0wVj7ZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the below code to see how the posterior compares to the ground truth HMM states. Change \"posterior\" to the variable name you used above."
      ],
      "metadata": {
        "id": "_M1YzIOqqqfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,3))\n",
        "\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(posterior)\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(Z)"
      ],
      "metadata": {
        "id": "Bi12grG6k0C-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "G) Calculate the accuracy of the posterior at estimating the ground truth latent states. Set a probability threshold of 0.5 to determine which of the two states is more likely."
      ],
      "metadata": {
        "id": "Lflc5a92sbnN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nV4liPiIkiy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "H) In words, in the text box below, describe why the HMM led to more accurate results than fitting with K-means.\n",
        "\n",
        "As a side note, this increase in accuracy is not just because we were cheating above and using the ground truth parameters. Fitting an HMM with EM gives similar results."
      ],
      "metadata": {
        "id": "g4SzoMDXvtaU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PrMzWBHdwL85"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Linear dynamical systems"
      ],
      "metadata": {
        "id": "PGL_KPi7uJY7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll be using the ssm package for fitting linear dynamical systems. Run the code below to install that package."
      ],
      "metadata": {
        "id": "0DWTCICafX0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/lindermanlab/ssm.git@master#egg=ssm\n",
        "\n",
        "import ssm"
      ],
      "metadata": {
        "id": "kVBXJCXIpjqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A) Fill in the code below to simulate data from a linear dynamical system model with 2-dimensional latents, with 5-dimensional observations.\n",
        "\n",
        "<br>\n",
        "The dynamics matrix is the scaled rotation matrix (which will cause the latents to spiral) :<br>\n",
        "$A = \\begin{bmatrix} cos(\\theta) & -sin(\\theta) \\\\ sin(\\theta) & cos(\\theta) \\end{bmatrix} \\text{for  } \\theta=\\pi/20$\n",
        "\n",
        "<br><br>\n",
        "In the code below, the emissions (observations) matrix is random, and there is more noise in the observations than the dynamics (see code below).\n"
      ],
      "metadata": {
        "id": "vpo3EIbyUV3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Dimensionality of latents\n",
        "K=2\n",
        "#Dimensionality of observations\n",
        "N=5\n",
        "\n",
        "#Initial latent state\n",
        "Z0=np.array([.5,.5])\n",
        "\n",
        "#Dynamics matrix\n",
        "th=np.pi/20\n",
        "A = .995 * np.array([[np.cos(th),-np.sin(th)],[np.sin(th),np.cos(th)]])\n",
        "\n",
        "#Noise of dynamics\n",
        "Sig_dynamics=.0001*np.identity(K)\n",
        "\n",
        "#Emissions (observations) matrix\n",
        "C=np.random.randn(K,N)\n",
        "\n",
        "#Noise of observations\n",
        "Sig_observations=.01*np.identity(N)\n",
        "\n",
        "#Number of time points to simulate for\n",
        "T=500\n",
        "\n",
        "#Initialize latents and observations\n",
        "Z = np.zeros((T,K))\n",
        "Y = np.zeros((T,N))\n",
        "\n",
        "#Set initial state (at time 0) of the latents\n",
        "Z[0]=Z0\n",
        "\n",
        "#Update observations at time t according to the latent state\n",
        "## FILL IN LINE BELOW ##\n",
        "Y[0]=\n",
        "\n",
        "# Loop over time points\n",
        "# At each time point, sample the next latent state (based on the dynamics matrix and the previous state),\n",
        "# and then determine the observation at that time point\n",
        "for t in range(1,T):\n",
        "  #Update latent state at time t according to dynamics\n",
        "  ## FILL IN LINE BELOW ##\n",
        "  Z[t]=\n",
        "\n",
        "  #Update observations at time t according to the latent state\n",
        "  ## FILL IN LINE BELOW ##\n",
        "  Y[t]="
      ],
      "metadata": {
        "id": "eD_hSVObfl1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the code below to plot the two dimensions of the latent against each other (to see the spiral if the above simulation is correct)"
      ],
      "metadata": {
        "id": "5o94ChP1cI2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(Z[:,0],Z[:,1])"
      ],
      "metadata": {
        "id": "JTh5Jw6ghy0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the code below to plot the two dimensions of the latent as a function of time"
      ],
      "metadata": {
        "id": "X_8VcVLtccEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(Z[:,0])\n",
        "plt.plot(Z[:,1])\n",
        "plt.legend(['Latent Dim 1','Latent Dim 2'])"
      ],
      "metadata": {
        "id": "en0ix02xc5NE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the code below to plot the first two dimensions of the observations as a function of time"
      ],
      "metadata": {
        "id": "9qwDCZbDczcx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(Y[:,0])\n",
        "plt.plot(Y[:,1])\n",
        "plt.legend(['Obs Dim 1','Obs Dim 2'])"
      ],
      "metadata": {
        "id": "GoLz3gvUZ8Mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "B) Fit a factor analysis model (using sci-kit learn) with 2 latents to the above observations"
      ],
      "metadata": {
        "id": "P7Hgvuo4dEcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fa=FactorAnalysis(2)\n",
        "z_fa=fa.fit_transform(Y)"
      ],
      "metadata": {
        "id": "r9_eEzMlb8yV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "C) Plot the 2 factor analysis latents as a function of time"
      ],
      "metadata": {
        "id": "UtoBB8KLhmQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(z_fa)"
      ],
      "metadata": {
        "id": "MnbH4whqb806"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "D) Fit an LDS model to the data\n",
        "\n",
        "You can run the ssm code below (no need to make any changes). Still, read through the code/comments to try to generally understand the below code."
      ],
      "metadata": {
        "id": "jAxkv1t3I_Jr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "obs_dim=N\n",
        "latent_dim=K\n",
        "\n",
        "#Define an LDS model that has a Gaussian emissions model, with the correct latent and observation dimensions\n",
        "lds = ssm.LDS(obs_dim, latent_dim, emissions=\"gaussian\")\n",
        "\n",
        "#Fit the LDS model using EM\n",
        "#Note the method says 'laplace_em', which becomes standard EM with Gaussian emissions\n",
        "elbos, q = lds.fit(Y, method=\"laplace_em\", num_iters=10)\n",
        "\n",
        "#The output q contains the posterior distribution (the latent's mean and variance)\n",
        "#Below, we'll just extract the mean of the posterior at each time point (the value we usually think of as the latent):\n",
        "z_lds = q.mean_continuous_states[0]"
      ],
      "metadata": {
        "id": "CtGFHN6dcQH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "E) Plot the latents learned by LDS"
      ],
      "metadata": {
        "id": "7z4JdsfJMxdi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UYnoz6fVcQK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "F) How do the learned latents differ between the factor analysis and LDS models? Why?  (Enter your answer in the text box below)"
      ],
      "metadata": {
        "id": "FIY9zGpdhwQn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "d8rh9Nl9hxTA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "G) Run the below code to check that the eigenvalues of the system's dynamics (the A matrix) were recovered correctly. Note that the eigenvectors, and the A matrices themselves won't be identical, because the emissions matrix can be recovered differently from the ground truth (e.g. some linear combination of the ground truth)."
      ],
      "metadata": {
        "id": "Erpgae8-AIvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Eigendecomposition of true dynamics\n",
        "np.linalg.eig(A)"
      ],
      "metadata": {
        "id": "JQXmYVMOB1vS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Eigendecomposition of learned dynamics\n",
        "np.linalg.eig(lds.dynamics.As)"
      ],
      "metadata": {
        "id": "o_tKIzdIB8eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) LDS on Real Neural Data"
      ],
      "metadata": {
        "id": "2HDf55WHjtzF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we're going to fit an LDS to some real neural data. This is data collected in Lee Miller's lab from motor cortex while a monkey continues to reach to targets across a workspace. All trials are concatenated together in time. <br>\n",
        "\n",
        "\"Neural data\" is a variable of size Timepoints x Neurons, where each entry is the firing rate of a given neuron in that time bin. <br>\n",
        "\"Velocity\" is a variable of size Timepoints x 2, where each timepoint has the x and y velocities of the hand.\n",
        "\n",
        "Each time bin, of both neural activity and velocity, is duration 50ms."
      ],
      "metadata": {
        "id": "zDYHQuPkiB69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Download and load the data\n",
        "\n",
        "!wget -nc https://www.dropbox.com/s/jcief15oql3tkll/example_data_m1.pickle?dl=0\n",
        "\n",
        "filename    = 'example_data_m1.pickle?dl=0'\n",
        "with open(filename, 'rb') as handle:\n",
        "    [Neural_data,Velocity] = pickle.load(handle)"
      ],
      "metadata": {
        "id": "Bh-MwjXRcQN_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7370e7c-6bfc-49e3-f22e-93537a8500ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File ‘example_data_m1.pickle?dl=0’ already there; not retrieving.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A) Fit a Factor Analysis model to the Neural data with 10 latents"
      ],
      "metadata": {
        "id": "xjUtLyqgj0-U"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uoNGNsCqfu9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "B) Fit a linear dynamical systems model to the neural data with 10 latents. Note that this will take a couple minutes to fit. You can just run the code below."
      ],
      "metadata": {
        "id": "xqbz29XNj7t7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "obs_dim=Neural_data.shape[1]\n",
        "latent_dim=10\n",
        "\n",
        "#Declare the LDS model\n",
        "lds = ssm.LDS(obs_dim, latent_dim, emissions=\"gaussian\")\n",
        "\n",
        "#Fit the LDS model\n",
        "elbos, q = lds.fit(Neural_data, method=\"laplace_em\", num_iters=10)\n",
        "\n",
        "#Get the latents:\n",
        "z_lds = q.mean_continuous_states[0]"
      ],
      "metadata": {
        "id": "ttGRFhuOoiyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "C) Plot the FA and LDS latents. You can just run the code below, but change the variable names as needed."
      ],
      "metadata": {
        "id": "vIT1iEcXengq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(z_fa[:200,:2])\n",
        "plt.title('FA latents')\n",
        "plt.xticks([])\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(z_lds[:200,:2])\n",
        "plt.title('LDS latents')\n"
      ],
      "metadata": {
        "id": "DZTcEvYzXn7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "D) At least to me, unlike the simulation example above, it's not obvious in the above plots that the LDS model has smoother latents. In the text box below, why do you think LDS doesn't lead to such smooth responses here. (Hint: There are realistically multiple reasons, but I'm mainly looking for whether LDS is a good model for this data, which contains an entire experiment concatenated together)."
      ],
      "metadata": {
        "id": "vDAA0vCNe1xh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iST0_316ggdV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "E) Still, let's quantitatively see how 'relatively smooth' the latents are. For each latent, we'll calculate the squared change in the latent at each time point, relative to the average squared magnitude of the latent. A smaller value will mean it's smoother (changing less from one time point to the next). We will then plot a histogram of this relative change. Run the below code cells"
      ],
      "metadata": {
        "id": "9-eHPpPqggs8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z=np.copy(z_fa)\n",
        "relative_change_fa=[np.mean((z[1:,l]-z[:-1,l])**2)/np.mean(z[:,l]**2) for l in range(10)]\n",
        "print(relative_change_fa)"
      ],
      "metadata": {
        "id": "xlnIEaBjsoAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z=np.copy(z_lds)\n",
        "relative_change_lds=[np.mean((z[1:,l]-z[:-1,l])**2)/np.mean(z[:,l]**2) for l in range(10)]\n",
        "print(relative_change_lds)"
      ],
      "metadata": {
        "id": "sw9yLjbUfoGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(relative_change_fa,alpha=0.5)\n",
        "plt.hist(relative_change_lds,alpha=0.5)\n",
        "plt.xlabel('Relative change (lower is smoother)')\n",
        "plt.ylabel('Number of latents')\n",
        "\n",
        "plt.legend(['FA','LDS'])"
      ],
      "metadata": {
        "id": "xYpchBGBiG-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "F) Does LDS lead to smoother latents (Yes or No)? Answer in the text box below."
      ],
      "metadata": {
        "id": "BXyILNE2DF3s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Fb_lD2udDPcC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "G) One way to validate that we are getting a better estimate of the underlying latents is to try to see which set of latents best relates to a separate, external variable (here, velocity).\n",
        "\n",
        "Fit decoding models from 1) the Factor analysis latents to velocity, and 2) the LDS latents to velocity, and see which leads to better performance.\n",
        "\n",
        "For the sake of time, you can do this is a non-rigorous (non-cross-validated way). Just report the \"score\" from two sci-kit learn linear regression models, where you train on all of the data."
      ],
      "metadata": {
        "id": "Xp_dqVOKkVLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit linear regression model based on factor analysis latents\n",
        "\n"
      ],
      "metadata": {
        "id": "s9y8Kooqt0t0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit linear regression model based on LDS latents\n",
        "\n"
      ],
      "metadata": {
        "id": "Y7hUAxV7tayg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cHuELMIatct4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}